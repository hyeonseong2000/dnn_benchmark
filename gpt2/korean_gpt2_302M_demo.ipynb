{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "한국어 GPT2 데모",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/affjljoo3581/GPT2/blob/master/korean_gpt2_302M_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYbOdA3ENjFx"
      },
      "source": [
        "# 한국어 GPT2 데모\n",
        "\n",
        "## Introduction\n",
        "이 노트북은 [affjljoo3581/GPT2](https://github.com/affjljoo3581/GPT2)를 통해 약 **5.04B**개의 토큰으로 학습된 **GPT2-302M** 모델을 사용하여 문장을 생성하는 예제입니다. 자세한 내용은 repository 및 issue를 확인해 주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZimL206uNtNP"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "제일 먼저 노트북의 Runtime Type이 GPU인지 확인해 주세요. 다음으로 아래의 셀을 통해 GPT2 레포지토리를 clone 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv6adDKVk44o"
      },
      "source": [
        "!git clone --quiet https://github.com/affjljoo3581/GPT2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJrTpBsHUJx4"
      },
      "source": [
        "학습된 한국어 GPT2 모델의 가중치를 다운로드 받습니다. 현재 지원하는 모델은 **GPT2-302M** 모델입니다. 자세한 사항은 다음과 같습니다.\n",
        "* maximum sequence length: 512\n",
        "* number of layers: 24\n",
        "* hidden_dim: 1024\n",
        "* number of attention heads: 16\n",
        "* bottleneck rate: 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD1EYuW2k9eI"
      },
      "source": [
        "!wget -q https://github.com/affjljoo3581/GPT2/releases/download/v0.1-korean/gpt2-ko-302M-512L.pth\n",
        "!wget -q https://github.com/affjljoo3581/GPT2/releases/download/v0.1-korean/vocab-ko-302M.txt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5mpBWPtQVpJ"
      },
      "source": [
        "## Generate Sentences!\n",
        "\n",
        "본 문서에서는 문장 생성을 위한 샘플링 기법으로 **nucleus sampling**을 사용합니다. **top-p sampling**으로도 불리는 이 기법은 **top-k sampling**과 함께 자연스러운 문장을 생성하는 것으로 잘 알려져 있습니다. 아래의 슬라이더를 통해 **top-p** 임계값을 정할 수 있습니다. 이후 셀을 실행하면 문장을 생성하기 위한 상호작용이 시작됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5SpOEralSZY"
      },
      "source": [
        "#@title Generation Options\n",
        "nucleus_prob = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "import IPython\n",
        "display(IPython.display.HTML('''<style> div.output_text pre {\n",
        "    white-space: pre-line; max-width: 1000px; display: inline-block;\n",
        "} </style>'''))\n",
        "\n",
        "!export PYTHONPATH=GPT2/src; python -m gpt2 generate \\\n",
        "        --vocab_path    vocab-ko-302M.txt \\\n",
        "        --model_path    gpt2-ko-302M-512L.pth \\\n",
        "        --seq_len       512 \\\n",
        "        --layers        24 \\\n",
        "        --heads         16 \\\n",
        "        --dims          1024 \\\n",
        "        --rate          4 \\\n",
        "        --nucleus_prob  $nucleus_prob \\\n",
        "        --use_gpu"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}